{"cells": [{"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["# Object Oriented Programming - Practice\n", "> Writing a Standard Scaler from Scratch\n", "\n", "In this notebook, we walkthrough the process of coding sklearn's StandardScaler class from scratch."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["# Run this cell unchanged\n", "# Import assignment packages\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.datasets import load_diabetes\n", "from sklearn.model_selection import train_test_split\n", "\n", "# Load data\n", "data = load_diabetes()\n", "df = pd.DataFrame(data['data'], columns = data['feature_names'])\n", "df['target'] = data['target']\n", "\n", "# Output preview of data\n", "df.head(2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 2}, "outputs": [], "source": ["# Run this cell unchanged\n", "# Import assignment packages\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.datasets import load_diabetes\n", "from sklearn.model_selection import train_test_split\n", "\n", "# Load data\n", "data = load_diabetes()\n", "df = pd.DataFrame(data['data'], columns = data['feature_names'])\n", "df['target'] = data['target']\n", "\n", "# Output preview of data\n", "df.head(2)"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["**Let's set up a train test split for our dataset**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["# Run this cell unchanged\n", "X = df.drop('target', axis = 1)\n", "y = df.target\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 5}, "outputs": [], "source": ["# Run this cell unchanged\n", "X = df.drop('target', axis = 1)\n", "y = df.target\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["**The process we will move through in this notebook will be the following:**\n", "1. Write `fit` and `transform` functions ***outside*** of a class. \n", "    * We want to get the code working before we throw it into a class.\n", "    \n", "2. Create a `StandardScaler` class with `fit` and `transform` methods\n", "    * We will need to add the `self` variable during this step. \n", "    \n", "3. Compare our results with Sklearn's"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["### fit"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["In the cell below, we have defined a function called `fit`. \n", "\n", "**This function should receive 1 argument.**\n", "1. `X` - A pandas dataframe or numpy array\n", "\n", "**This function should execute the following steps:**\n", "1. Convert `X` to a numpy array by passing the input into `np.array`.\n", "    * To loop over the index of a pandas dataframe, we use `.iloc`, ie `df.iloc[:,0]` will return the first column of a dataframe, but numpy does not have an `.iloc` method. To avoid an error, the easiest solution is to ensure the input is a numpy array.\n", "    \n", "3. Loop over the columns of the numpy array.\n", "4. For each column, calculate the mean and standard deviation\n", "5. Store the statistics in the container as a tuple with the following format:\n", "```python\n", "(mean, standard_deviation)\n", "```"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["container = []\n", "\n", "def fit(X):\n", "    # Convert X to a numpy array by passing the input into np.array\n", "    \n", "    # Loop over the columns of the numpy array.\n", "    \n", "        # For each column, calculate the mean and standard deviation\n", "        \n", "        # Store the statistics in the container"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 10}, "outputs": [], "source": ["container = []\n", "\n", "def fit(X):\n", "    # Convert X to a numpy array by passing the input into np.array\n", "    X_ = np.array(X)\n", "    # Loop over the columns of the numpy array.\n", "    for column in range(X_.shape[1]):\n", "        # For each column, calculate the mean and standard deviation\n", "        mean = X_[:, column].mean()\n", "        std = X_[:, column].std()\n", "        # Store the statistics in the container\n", "        container.append((mean, std))"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["Let's test our function on our X_train"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["# Run this cell unchanged\n", "\n", "from src.public_tests import test_fit\n", "# Create container\n", "container = []\n", "# Run fit function\n", "fit(X_train)\n", "# Test results\n", "test_fit(container)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 13}, "outputs": [], "source": ["# Run this cell unchanged\n", "\n", "from src.public_tests import test_fit\n", "# Create container\n", "container = []\n", "# Run fit function\n", "fit(X_train)\n", "# Test results\n", "test_fit(container)"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["### transform\n", "\n", "Below we define function called `transform`. \n", "\n", "**This function should receive 1 argument**\n", "1. `X` - Pandas dataframe or numpy array\n", "\n", "**This function should execute the following steps:**\n", "1. Convert X to a numpy array by passing the input into np.array\n", "2. Loop over the columns of X\n", "3. Access the mean and standard deviation that were created from the `fit` function and stored in the container variable.\n", "4. Subtract the mean from the column and divide by the standard deviation.\n", "5. Return the transformed version of X"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["def transform(X):\n", "    # Convert X to a numpy array by passing the input into np.array\n", "    \n", "    # Loop over the columns of X\n", "    \n", "        # Access the mean and standard deviation that were \n", "        # created from the fit function and stored in the container variable.\n", "        \n", "        # Subtract the mean from the column \n", "        # and divide by the standard deviation.\n", "        \n", "    # Return the transformed version of X"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 16}, "outputs": [], "source": ["def transform(X):\n", "    # Convert X to a numpy array by passing the input into np.array\n", "    X_ = np.array(X)\n", "    # Loop over the columns of X\n", "    for column in range(X_.shape[1]):\n", "        # Access the mean and standard deviation that were \n", "        # created from the fit function and stored in the container variable.\n", "        mean = container[column][0]\n", "        std = container[column][1]\n", "        # Subtract the mean from the column \n", "        # and divide by the standard deviation.\n", "        X_[:, column] = (X_[:, column] - mean)/std\n", "    # Return the transformed version of X  \n", "    return X_"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["Let's test our `transform` function on the training data!"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["from src.public_tests import test_transform\n", "\n", "container = []\n", "fit(X_train)\n", "X_train_scaled = transform(X_train)\n", "test_transform(X_train_scaled[:5])"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 19}, "outputs": [], "source": ["from src.public_tests import test_transform\n", "\n", "container = []\n", "fit(X_train)\n", "X_train_scaled = transform(X_train)\n", "test_transform(X_train_scaled[:5])"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["## Move our code into a `StandardScaler` class!\n", "\n", "**Please complete the StandardScaler class**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["class StandardScaler:\n", "    \n", "    def fit():\n", "        \n", "    def transform():"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 22}, "outputs": [], "source": ["class StandardScaler:\n", "    \n", "    def fit(self, X):\n", "        # Create a container to store the statistics\n", "        self.data = []\n", "        # Convert X to a numpy array by passing the input into np.array\n", "        X_ = np.array(X)\n", "        # Loop over the columns of the numpy array.\n", "        for column in range(X_.shape[1]):\n", "            # For each column, calculate the mean and standard deviation\n", "            mean = X_[:, column].mean()\n", "            std = X_[:, column].std()\n", "            # Store the statistics in the container\n", "            self.data.append((mean, std))\n", "            \n", "    def transform(self, X):\n", "        # Convert X to a numpy array by passing the input into np.array\n", "        X_ = np.array(X)\n", "        # Loop over the columns of X\n", "        for column in range(X_.shape[1]):\n", "            # Access the mean and standard deviation that were \n", "            # created from the fit function and stored in the container variable.\n", "            mean = self.data[column][0]\n", "            std = self.data[column][1]\n", "            # Subtract the mean from the column \n", "            # and divide by the standard deviation.\n", "            X_[:, column] = (X_[:, column] - mean)/std\n", "        # Return the transformed version of X  \n", "        return X_"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["Now let's compare our results with Sklearn's scaler!"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler as SklearnScaler"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 25}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler as SklearnScaler"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["# Create an instance of our scaler\n", "our_scaler = StandardScaler()\n", "our_scaler.fit(X_train)\n", "\n", "# Create an instance of sklearn's scaler\n", "sk_scaler = SklearnScaler()\n", "sk_scaler.fit(X_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 27}, "outputs": [], "source": ["# Create an instance of our scaler\n", "our_scaler = StandardScaler()\n", "our_scaler.fit(X_train)\n", "\n", "# Create an instance of sklearn's scaler\n", "sk_scaler = SklearnScaler()\n", "sk_scaler.fit(X_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["# Scaler train with our scaler\n", "our_scaled_train = our_scaler.transform(X_train)\n", "sk_scaled_train = sk_scaler.transform(X_train)\n", "\n", "# Scaler test with our scaler\n", "our_scaled_test = our_scaler.transform(X_test)\n", "sk_scaled_test = sk_scaler.transform(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 29}, "outputs": [], "source": ["# Scaler train with our scaler\n", "our_scaled_train = our_scaler.transform(X_train)\n", "sk_scaled_train = sk_scaler.transform(X_train)\n", "\n", "# Scaler test with our scaler\n", "our_scaled_test = our_scaler.transform(X_test)\n", "sk_scaled_test = sk_scaler.transform(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["# Check if our scaled train is the same as sklearn's\n", "np.all(our_scaled_train == sk_scaled_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 31}, "outputs": [], "source": ["# Check if our scaled train is the same as sklearn's\n", "np.all(our_scaled_train == sk_scaled_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": "Placeholder"}, "outputs": [], "source": ["# Check if our scaled test is the same as sklearn's\n", "np.all(our_scaled_test == sk_scaled_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 33}, "outputs": [], "source": ["# Check if our scaled test is the same as sklearn's\n", "np.all(our_scaled_test == sk_scaled_test)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}